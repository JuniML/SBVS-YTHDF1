{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f05c5566",
   "metadata": {},
   "source": [
    "# Training and testing target-specific machine-learning models for structure-based virtual screening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cdbaaf",
   "metadata": {},
   "source": [
    "This Jupyter notebook helps users train and test target-specific classification-based machine-learning models for structure-based virtual screening using PLEC features.\n",
    "\n",
    "Additional information can be found in our Nature Protocols paper: Tran-Nguyen, V. K., Junaid, M., Simeon, S. & Ballester, P. J. A practical guide to machine-learning scoring for structure-based virtual screening. Nat. Protoc. (2023)\n",
    "\n",
    "We recommend users to set up the protocol-env environment before running the code in this Jupyter notebook. This can be done using the protocol-env.yml file in our MLSF-protocol github repository: https://github.com/vktrannguyen/MLSF-protocol.\n",
    "\n",
    "For deepcoys generation, please use the github repository https://github.com/fimrie/DeepCoy/tree/master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc534f69",
   "metadata": {},
   "source": [
    "## 1. Import all necessary Python packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cc13a0",
   "metadata": {},
   "source": [
    "The following libraries/packages/toolkits need to be installed beforehand: jupyter notebook, pandas, oddt, sklearn, xgboost, rdkit, deepchem, joblib, tqdm, glob, tensorflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38435f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import oddt\n",
    "import oddt.pandas as opd\n",
    "from oddt.pandas import ChemDataFrame\n",
    "from oddt.fingerprints import PLEC\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import matthews_corrcoef, precision_recall_curve, accuracy_score, auc\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils import parallel_backend\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import tempfile\n",
    "import hyperopt\n",
    "from hyperopt import hp, tpe, Trials, fmin, STATUS_OK, space_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c8a785",
   "metadata": {},
   "source": [
    "## 2. Load smile files for train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b85465",
   "metadata": {},
   "source": [
    "Examples of these csv data files are provided in our MLSF-protocol github repository: https://github.com/vktrannguyen/MLSF-protocol. Please refer to our Nature Protocols paper cited above for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b74fa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Provide the pathway to the csv training data file:\n",
    "train_data = pd.read_csv(\"pathway_to_training-set_csv_data_file\")\n",
    "\n",
    "#Provide the pathway to the csv test data file:\n",
    "test_data = pd.read_csv(\"pathway_to_test-set_csv_data_file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707d1eb0-4bd3-41ff-9d63-241a1ed90f63",
   "metadata": {},
   "source": [
    "## 3. Convert smiles to mol2 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad985f16-136d-44df-b556-1e71a9624e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,smi in enumerate(chem_file_1_smiles):\n",
    "    mol=pybel.readstring(string=smi,format='smiles')\n",
    "    mol.title='mol_'+str(index)\n",
    "    mol.make3D('mmff94s')\n",
    "    mol.localopt(forcefield='mmff94s', steps=500)\n",
    "    out=pybel.Outputfile(filename='/path_for_mol2_files/'+'mol_'+str(index)+'.mol2',format='mol2',overwrite=True)\n",
    "    out.write(mol)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ccbceb-89b0-4b42-b0a7-53025be13a1d",
   "metadata": {},
   "source": [
    "## 4. Generate 30 conformation for each molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3f1725-fb4e-4d64-96f8-3af26182c290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_conformers_and_save_sdf(smiles_list, max_conformers=30):\n",
    "    for idx, smiles in enumerate(smiles_list):\n",
    "        mol = pybel.readstring(\"smi\", smiles)\n",
    "        mol.make3D()\n",
    "\n",
    "        for conformer_num in range(1, max_conformers + 1):\n",
    "            mol_copy = mol.clone\n",
    "            mol_copy.localopt(forcefield=\"mmff94\", steps=500)  # Perform local optimization\n",
    "            sdf_filename = f\"mol_{idx+1}_{conformer_num}.mol2\"\n",
    "            mol_copy.write(\"mol2\", sdf_filename, overwrite=True)\n",
    "generate_conformers_and_save_sdf(smiles_list, max_conformers=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14a027a-788e-4c30-86c5-b895b1d97aa9",
   "metadata": {},
   "source": [
    "## 5. Run docking using smina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f552596e-2ba7-4e11-900a-e3e2628d6751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_smina(input_file):\n",
    "    receptor_path = ['path_to_receptor_pdb_file']\n",
    "    input_path = ['path_to_mol2_files' + str(input_file)]\n",
    "    output_path = ['path_for_output_docked_poses/' + str(input_file)[:-5] +  '_docked.sdf']\n",
    "    smina_command = ['path_to_smina_code/smina -r '+ str(receptor_path[0])+ \n",
    "                    ' -l '+str(input_file)+ ' -o '+str(output_path[0])+ ' --center_x ' +str(center['center_x'])+\n",
    "                    ' --center_y '+str(center['center_y'])+ ' --center_z '+str(center['center_z'])+ \n",
    "                    ' --size_x '+ str(size['size_x'])+ ' --size_y '+ str(size['size_y'])+ ' --size_z '+ str(size['size_z'])+ ' --exhaustiveness 8 --num_modes 1']\n",
    "    os.system(smina_command[0])\n",
    "    \n",
    "Parallel(n_jobs = 40, backend = 'multiprocessing')(delayed(run_smina)(input_file) for input_file in tqdm(input_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d873f120-cc1d-4da1-9f05-b2daf2c577d6",
   "metadata": {},
   "source": [
    "## 6. Extract PLEC fingerprints from input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5f910b-3a46-4dd0-a7f9-ff373b952aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein = next(oddt.toolkit.readfile('pdb', 'path_to_receptor_structure'))\n",
    "def parallel_plec(lig):\n",
    "    ligand = next(oddt.toolkit.readfile('sdf', lig))\n",
    "    feature = PLEC(ligand, protein = protein, size = 4092, \n",
    "                  depth_protein = 4, depth_ligand = 2,\n",
    "                  distance_cutoff = 4.5, sparse = False)\n",
    "    return feature\n",
    "plec_training_actives = Parallel(n_jobs = 40, backend = \"multiprocessing\")(delayed(parallel_plec)(mol) for mol in tqdm(docked_sdf_active))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa18ea7",
   "metadata": {},
   "source": [
    "## 7. Train and test the RF algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c0200e-ba8b-4067-90c7-992e1de49d7b",
   "metadata": {},
   "source": [
    "hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00642a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the search space for optimal parameters:\n",
    "space = {\"n_estimators\": hp.uniform(\"n_estimators\", 50, 10000),\n",
    "         \"max_depth\": hp.choice(\"max_depth\", [1, 2, 3, 4, 5, None]),\n",
    "         \"criterion\": hp.choice(\"criterion\", ['gini', 'entropy']),\n",
    "         'min_samples_leaf':hp.randint('min_samples_leaf',1,5),\n",
    "         'min_samples_split':hp.randint('min_samples_split',2,6)}\n",
    "\n",
    "#Define the function for hyperparameter tuning:\n",
    "def hyperparameter_tuning_randomforest(space):\n",
    "    model = RandomForestClassifier(**space, n_jobs = 40)\n",
    "    model.fit(np.array(train_features), Train_Class)\n",
    "    predicted_train = model.predict(np.array(train_features))\n",
    "    mcc = matthews_corrcoef(Train_Class, predicted_train)\n",
    "    return {'loss': 1-mcc, 'status': STATUS_OK, 'model': model}\n",
    "    \n",
    "#Search for optimal parameters:\n",
    "trials = Trials()\n",
    "best_rf_classification = fmin(fn = hyperparameter_tuning_randomforest, space = space, algo = tpe.suggest,\n",
    "                              max_evals = 10, trials = trials)\n",
    "best_params = space_eval(space, best_rf_classification)\n",
    "\n",
    "#Optimal parameters:\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb85b0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the RF model on the training molecules, using optimal parameters:\n",
    "rf_plec = RandomForestClassifier(n_estimators = int(best_params['n_estimators']), \n",
    "                                 max_depth = best_params['max_depth'], \n",
    "                                 criterion = best_params['criterion'],\n",
    "                                 min_samples_split = best_params['min_samples_split'],\n",
    "                                 min_samples_leaf = best_params['min_samples_leaf']\n",
    "                                 n_jobs = 30)\n",
    "rf_plec.fit(train_features, Train_Class)\n",
    "\n",
    "#Test the RF model on the test molecules:\n",
    "prediction_test_rf_plec_class = rf_plec.predict(test_features)\n",
    "prediction_test_rf_plec_prob = rf_plec.predict_proba(test_features)\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "plec_result_rf = pd.DataFrame({\"Active_Prob\": prediction_test_rf_plec_prob[:, 0],\n",
    "                               \"Inactive_Prob\": prediction_test_rf_plec_prob[:, 1],\n",
    "                               \"Predicted_Class\": prediction_test_rf_plec_class,\n",
    "                               \"Real_Class\": Test_Class})\n",
    "plec_result_rf.to_csv(\"where_you_want_to_store_the_csv_output_file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aba96b0",
   "metadata": {},
   "source": [
    "## 8. Train and test the XGB algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda082a4",
   "metadata": {},
   "source": [
    "hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870a5ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=5\n",
    "def objective_plec_2(params):\n",
    "    xgb_plec=xgb.XGBClassifier(**params, n_jobs=40, random_state=seed)\n",
    "    xgb_plec.fit(X_train_plec,y_train_plec)\n",
    "    pred_xgb_plec=xgb_plec.predict(X_val_plec)\n",
    "    accuracy = accuracy_score(y_val_plec, pred_xgb_plec)\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK}\n",
    "\n",
    "params={'n_estimators':hp.randint('n_estimators',100,500),\n",
    "           'max_depth':hp.randint('max_depth',5,20),\n",
    "           'learning_rate':hp.choice('learning_rate',[0.01,0.1])}\n",
    "\n",
    "def optimize_plec_2(trial_xgb_plec):\n",
    "\n",
    "    best_plec_2=fmin(fn=objective_plec_2,\n",
    "                     space=params,\n",
    "                     algo=tpe.suggest,\n",
    "                     max_evals=500,\n",
    "                     rstate=np.random.default_rng(seed))\n",
    "    return best_plec_2\n",
    "\n",
    "trial_xgb_plec=Trials()\n",
    "best_xgb_plec=optimize_plec_2(trial_xgb_plec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1cdd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the XGB model on the training molecules, using optimal parameters:\n",
    "xgb_plec = XGBClassifier(max_depth = int(best_params['max_depth']),\n",
    "                         n_estimators = int(best_params['n_estimators']),\n",
    "                         learning_rate = int(best_params['learning_rate'])\n",
    "                         n_jobs = 40, random_state = 0)\n",
    "xgb_plec.fit(np.array(train_features), Train_Class)\n",
    "\n",
    "#Test the XGB model on the test molecules:\n",
    "prediction_test_xgb_plec_class = xgb_plec.predict(np.array(test_features))\n",
    "prediction_test_xgb_plec_prob = xgb_plec.predict_proba(np.array(test_features))\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "plec_result_xgb = pd.DataFrame({\"Active_Prob\": prediction_test_xgb_plec_prob[:, 0],\n",
    "                                \"Inactive_Prob\": prediction_test_xgb_plec_prob[:, 1],\n",
    "                                \"Predicted_Class\": prediction_test_xgb_plec_class,\n",
    "                                \"Real_Class\": Test_Class})\n",
    "plec_result_xgb.to_csv(\"where_you_want_to_store_the_csv_output_file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf9521e",
   "metadata": {},
   "source": [
    "## 9. Train and test the SVM algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3044eb",
   "metadata": {},
   "source": [
    "hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7064937d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the search space for optimal parameters:\n",
    "space = {\"C\": hp.uniform(\"C\", 0, 20),\n",
    "         \"gamma\": hp.choice(\"gamma\", ['scale', 'auto']),\n",
    "         \"kernel\": hp.choice(\"kernel\", ['rbf', 'poly', 'sigmoid'])}\n",
    "\n",
    "#Define the function for hyperparameter tuning:\n",
    "def hyperparameter_tuning_SVM(space):\n",
    "    with parallel_backend(backend = \"multiprocessing\", n_jobs = 40):\n",
    "        model = SVC(C = space['C'],\n",
    "                    gamma = space['gamma'],\n",
    "                    kernel = space['kernel'])\n",
    "        model.fit(np.array(train_features), Train_Class)\n",
    "        predicted_train = model.predict(np.array(train_features))\n",
    "        mcc = matthews_corrcoef(Train_Class, predicted_train)\n",
    "    return {'loss': 1-mcc, 'status': STATUS_OK, 'model': model}\n",
    "        \n",
    "#Search for optimal parameters:\n",
    "trials = Trials()\n",
    "best_svm_classification = fmin(fn = hyperparameter_tuning_SVM, space = space, algo = tpe.suggest,\n",
    "                               max_evals = 10, trials = trials)\n",
    "best_params = space_eval(space, best_svm_classification)\n",
    "\n",
    "#Optimal parameters:\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a937e93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the SVM model on the training molecules, using optimal parameters:\n",
    "svm_plec = SVC(C = best_params['C'], gamma = best_params['gamma'], kernel = best_params['kernel'], \n",
    "               probability = True, random_state = 0)\n",
    "svm_plec.fit(train_features, Train_Class)\n",
    "\n",
    "#Test the SVM model on the test molecules:\n",
    "prediction_test_svm_plec_class = svm_plec.predict(test_features)\n",
    "prediction_test_svm_plec_prob = svm_plec.predict_proba(test_features)\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "plec_result_svm  = pd.DataFrame({\"Active_Prob\": prediction_test_svm_plec_prob[:, 0],\n",
    "                                 \"Inactive_Prob\": prediction_test_svm_plec_prob[:, 1],\n",
    "                                 \"Predicted_Class\": prediction_test_svm_plec_class,\n",
    "                                 \"Real_Class\": Test_Class})\n",
    "plec_result_svm.to_csv(\"where_you_want_to_store_the_csv_output_file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2f8c27",
   "metadata": {},
   "source": [
    "## 10. Train and test the ANN algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec22948",
   "metadata": {},
   "source": [
    "hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d83ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the search space for optimal parameters:\n",
    "space = {\"hidden_layer_sizes\": hp.uniform(\"hidden_layer_sizes\", 8, 140),\n",
    "         \"activation\": hp.choice(\"activation\", ['relu', 'tanh']),\n",
    "         \"max_iter\": hp.uniform(\"max_iter\", 1000, 10000)}\n",
    "\n",
    "#Define the function for hyperparameter tuning:\n",
    "def hyperparameter_tuning_ANN(space):\n",
    "    model = MLPClassifier(hidden_layer_sizes = int(space['hidden_layer_sizes']),\n",
    "                          activation = space['activation'],\n",
    "                          max_iter = int(space['max_iter']))\n",
    "    model.fit(np.array(train_features), Train_Class)\n",
    "    predicted_train = model.predict(np.array(train_features))\n",
    "    mcc = matthews_corrcoef(Train_Class, predicted_train)\n",
    "    return {'loss': 1-mcc, 'status': STATUS_OK, 'model': model}\n",
    "    \n",
    "#Search for optimal parameters:\n",
    "trials = Trials()\n",
    "best_ann_classification = fmin(fn = hyperparameter_tuning_ANN, space = space, algo = tpe.suggest,\n",
    "                               max_evals = 10, trials = trials)\n",
    "best_params = space_eval(space, best_ann_classification)\n",
    "\n",
    "#Optimal parameters:\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b1bf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the ANN model on the training molecules, using optimal parameters:\n",
    "ann_plec = MLPClassifier(hidden_layer_sizes = int(best_params['hidden_layer_sizes']), \n",
    "                         activation = best_params['activation'], \n",
    "                         max_iter = int(best_params['max_iter']), \n",
    "                         random_state = 0)\n",
    "ann_plec.fit(train_features, Train_Class)\n",
    "\n",
    "#Test the ANN model on the test molecules:\n",
    "prediction_test_ann_plec_class = ann_plec.predict(test_features)\n",
    "prediction_test_ann_plec_prob = ann_plec.predict_proba(test_features)\n",
    "\n",
    "#Get virtual screening results on the test molecules and export results to a csv file:\n",
    "plec_result_ann = pd.DataFrame({\"Active_Prob\": prediction_test_ann_plec_prob[:, 0],\n",
    "                                \"Inactive_Prob\": prediction_test_ann_plec_prob[:, 1],\n",
    "                                \"Predicted_Class\": prediction_test_ann_plec_class,\n",
    "                                \"Real_Class\": Test_Class})\n",
    "plec_result_ann.to_csv(\"where_you_want_to_store_the_csv_output_file\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
